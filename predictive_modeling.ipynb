{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/AllisonOge/predictive_modeling/blob/main/predictive_modeling.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "GT59gi4kI12v"
      },
      "outputs": [],
      "source": [
        "# import tflite_runtime.interpreter as tflite\n",
        "import tensorflow.lite as tflite\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "# import tensorflow as tf\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# utility function\n",
        "def start_and_idle_time(bit_sequence):\n",
        "    bit_sequence = np.asarray(bit_sequence, dtype=np.int32)\n",
        "    start_time = 0\n",
        "    idle_time = 0\n",
        "    idle_times = []\n",
        "    for i, bit in enumerate(bit_sequence):\n",
        "        # print(i, bit)\n",
        "        if i > 0:\n",
        "            if bit == 0 and bit_sequence[i-1] == 1:\n",
        "                # 1,0\n",
        "                start_time = i\n",
        "                idle_time += 1\n",
        "            elif bit == 0 and bit_sequence[i-1] == 0:\n",
        "                # 0,0\n",
        "                idle_time += 1\n",
        "            elif bit == 1 and bit_sequence[i-1] == 0:\n",
        "                # 0,1\n",
        "                idle_times.append((start_time, idle_time))\n",
        "                idle_time = 0\n",
        "            else:\n",
        "                # 1,1\n",
        "                continue\n",
        "        else:\n",
        "            if bit == 0:\n",
        "                start_time = i\n",
        "                idle_time += 1\n",
        "\n",
        "        if i == len(bit_sequence)-1 and idle_time > 0:\n",
        "            idle_times.append((start_time, idle_time))\n",
        "\n",
        "    return np.array(idle_times)"
      ],
      "metadata": {
        "id": "-MsWuTknJofX"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "NldZBVGsI12-"
      },
      "outputs": [],
      "source": [
        "class ML:\n",
        "    \"\"\"ML Parent Class to prepare the data and load model\n",
        "       Attributes\n",
        "       ----------\n",
        "            dataset: (Array-like) saves the latest channel state within window size\n",
        "            name: (string) name of the model\n",
        "            window_size:(int) length of channel state to store in memory (default=10)\n",
        "            model_interpreter: tflite interpreter to load model\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "            update_dataset(channel_state)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str, window_size: int = 10, model_path: str = os.path.abspath(\"./models/model.tflite\")):\n",
        "        self.dataset: list = []\n",
        "        self.name = name\n",
        "        self.window_size: int = window_size\n",
        "        self.model_interpreter = tflite.Interpreter(model_path=model_path)\n",
        "        # allocate memory\n",
        "        self.model_interpreter.allocate_tensors()\n",
        "        self.selected_channel = None\n",
        "\n",
        "    def update_dataset(self, channel_state: list) -> None:\n",
        "        \"\"\"Update the dataset buffer\n",
        "\n",
        "           Parameters\n",
        "           ----------\n",
        "                channel_state: (1-D Array-like) state of the channel\n",
        "\n",
        "            Return \n",
        "            ------\n",
        "                None\n",
        "        \"\"\"\n",
        "        self.dataset.append(channel_state)\n",
        "\n",
        "    def get_prediction(self, channel_state) -> None or dict:\n",
        "        \"\"\"Prepare data and invoke model inference\n",
        "\n",
        "           Parameters\n",
        "           ----------\n",
        "                channel_state: (1-D Array-like) state of the channel\n",
        "\n",
        "            Return\n",
        "            ------\n",
        "                None or predictions\n",
        "        \"\"\"\n",
        "        # update dataset and reshape to window size\n",
        "        self.update_dataset(channel_state)\n",
        "\n",
        "        if not len(self.dataset) >= self.window_size:\n",
        "            return\n",
        "\n",
        "        self.dataset = self.dataset[:self.window_size]\n",
        "\n",
        "        # set input tensor for the model\n",
        "        X = np.array([r for r in self.dataset], dtype=np.float32).reshape(\n",
        "            (-1, self.window_size, len(channel_state)))\n",
        "\n",
        "        idx = self.model_interpreter.get_input_details()[0][\"index\"]\n",
        "        # set input tensor\n",
        "        self.model_interpreter.set_tensor(idx, X)\n",
        "        # invoke predictions\n",
        "        self.model_interpreter.invoke()\n",
        "\n",
        "        idx = self.model_interpreter.get_output_details()[0][\"index\"]\n",
        "        return self.model_interpreter.get_tensor(idx)\n",
        "\n",
        "    def select_channel(self, channel_state):\n",
        "        pass\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ohyCnJIzI13K"
      },
      "source": [
        "# Model 1: predicts the next state\n",
        "\n",
        "## Algorithm\n",
        "\n",
        "- for every time slot get the predictions and select the channel with free state whose occupancy is the lowest from past data\n",
        "- repeat for every time slot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {
        "id": "nLX_xbDRI13N"
      },
      "outputs": [],
      "source": [
        "class CS1(ML):\n",
        "    \"\"\"Channel Selection Algorithm 1\n",
        "\n",
        "       Make inference on the next state of the channel and selects a channel \n",
        "       with the least occupancy\n",
        "\n",
        "       Attributes\n",
        "       ----------\n",
        "        occ_sum: (list)\n",
        "        occupancies: (list)\n",
        "        counter: (int)\n",
        "    \"\"\"\n",
        "\n",
        "    def __init__(self, name: str, nchannels: int, window_size: int = 10, model_path=...):\n",
        "        super().__init__(name, window_size, model_path)\n",
        "        self.occ_sums = []\n",
        "        self.occupancies = [0, ] * nchannels\n",
        "        self.counter = 0\n",
        "\n",
        "    def update_dataset(self, channel_state):\n",
        "        self.dataset.append(channel_state)\n",
        "        self.occupancies = self.update_occupancies(channel_state)\n",
        "\n",
        "    def update_occupancies(self, channel_state):\n",
        "        \"\"\"Compute the latest occupancies of the channel\n",
        "\n",
        "           Steps:\n",
        "                update the sums of states and increment counter\n",
        "                new occupancy = sum of states / counter\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "\n",
        "        \"\"\"\n",
        "        if len(self.occ_sums) > 0:\n",
        "          self.occ_sums = [r+channel_state[i]\n",
        "                          for i, r in enumerate(self.occ_sums)]\n",
        "        else:\n",
        "          self.occ_sums = channel_state\n",
        "\n",
        "        self.counter += 1\n",
        "        return [o / self.counter for o in self.occ_sums]\n",
        "\n",
        "    def select_channel(self, channel_state):\n",
        "        \"\"\"Make predictions and select the channel with the least occupancy\n",
        "\n",
        "           Parameters\n",
        "           ----------\n",
        "                channel_state: (1-D array-like) state of the channel\n",
        "\n",
        "            Returns\n",
        "            -------\n",
        "                None or selected_channel\n",
        "        \"\"\"\n",
        "        channel_state = list(channel_state)\n",
        "        # get predictions\n",
        "        preds = self.get_prediction(channel_state)\n",
        "        if preds is None:\n",
        "            return\n",
        "\n",
        "        preds = (np.array(preds).flatten() > 0.5).astype(int)\n",
        "        free_channels = [i for i, s in enumerate(preds) if s == 0]\n",
        "        # no channel is free\n",
        "        if len(free_channels) == 0:\n",
        "            return\n",
        "        if self.selected_channel in free_channels:\n",
        "            return self.selected_channel\n",
        "        # only one channel\n",
        "        if len(free_channels) == 1:\n",
        "            self.selected_channel = free_channels[0]\n",
        "            return self.selected_channel\n",
        "        # select the least occupancy\n",
        "        latest_occ = [i for i, _ in enumerate(\n",
        "            self.occupancies) if i in free_channels]\n",
        "        self.selected_channel = [i for i, val in enumerate(\n",
        "            latest_occ) if val == min(latest_occ)][0]\n",
        "        return self.selected_channel\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q5y3JemgI13S"
      },
      "source": [
        "# Model 2: predicts the idle time\n",
        "\n",
        "## Algorithm\n",
        "\n",
        "- for every time slot get the predictions and select channel with higher idle time prediction\n",
        "- repeat for every time slot\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "8jfjPlJfI13W"
      },
      "outputs": [],
      "source": [
        "class CS2(ML):\n",
        "    \"\"\"Channel Selection Algorithm 2\n",
        "\n",
        "       Make inference on the idle time of the channel \n",
        "       and select channel with highest idle time\n",
        "\n",
        "       Attributes\n",
        "       ----------\n",
        "            dataset: (Array-like) saves the latest channel state within window size\n",
        "            window_size:(int) length of channel state to store in memory (default=10)\n",
        "            model_interpreter: tflite interpreter to load model\n",
        "            selected_channel: (int) channel selected by algorithm\n",
        "\n",
        "        Methods\n",
        "        -------\n",
        "            update_dataset(channel_state)\n",
        "\n",
        "    \"\"\"\n",
        "\n",
        "    def prepare_dataset(self):\n",
        "        \"\"\" Compute the idletimes of the channel states sequence\n",
        "            stored in dataset and updates it\n",
        "\n",
        "            This method transforms the bits of ones and zeros to\n",
        "            the idle time at each time slot e.g., a sequence of \n",
        "            [1, 0, 0, 0, 1, 0, 1] has the idle time representation\n",
        "            of [0, 3, 2, 1, 0, 1, 0]\n",
        "\n",
        "            Given the channel states tensor it transforms it to the\n",
        "            corresponding idle times\n",
        "\n",
        "            Parameters\n",
        "            ----------\n",
        "              None\n",
        "\n",
        "            Returns\n",
        "            -------\n",
        "              None\n",
        "        \"\"\"\n",
        "        idle_times = []\n",
        "        for i in range(len(self.dataset)):\n",
        "            idle_times.append([j[0][1] if len(j) > 0 and i+j[0][0] <= i else 0\n",
        "                               for j in list(map(start_and_idle_time, np.transpose(self.dataset[i:])))])\n",
        "        self.dataset = [r for r in idle_times]\n",
        "\n",
        "    def select_channel(self, channel_state) -> None or int:\n",
        "        \"\"\"Select a channel with highest idle time prediction\n",
        "\n",
        "           Parameters\n",
        "           ----------\n",
        "                channel_state: (1-D array-like) state of the channel\n",
        "\n",
        "            Returns\n",
        "            -------\n",
        "                None or selected_channel\n",
        "\n",
        "        \"\"\"\n",
        "        channel_state = list(channel_state)\n",
        "        self.update_dataset(channel_state)\n",
        "        if not len(self.dataset) >= self.window_size:\n",
        "            return\n",
        "        # prepare the data\n",
        "        self.prepare_dataset()\n",
        "        # get predictions\n",
        "        preds = self.get_prediction(channel_state)\n",
        "        preds = np.array(preds).flatten()\n",
        "\n",
        "        if preds is None:\n",
        "            return\n",
        "        # if no channel is free\n",
        "        if max(preds) <= 0:\n",
        "            return\n",
        "        # select channel of highest idle time\n",
        "        self.selected_channel = [\n",
        "            i for i, val in enumerate(preds) if val == max(preds)][0]\n",
        "        return self.selected_channel"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Test the models 🧪"
      ],
      "metadata": {
        "id": "fgTPir0ZJDEf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "\n",
        "data = pd.read_csv(\"https://raw.githubusercontent.com/AllisonOge/predictive_modeling/main/sensor_ml.csv\", index_col=\"id\")\n",
        "data = data.drop_duplicates(subset=\"created_at\")\n",
        "sensor = data[[\"chan_1\", \"chan_2\", \"chan_3\", \"chan_4\"]].to_numpy()"
      ],
      "metadata": {
        "id": "29dRKqkuKSzA"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sensor"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rkbhsG6pLORZ",
        "outputId": "2727b185-7215-4498-a0db-e18b3f2f876c"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1, 1, 0, 1],\n",
              "       [1, 1, 0, 1],\n",
              "       [1, 1, 0, 1],\n",
              "       ...,\n",
              "       [1, 1, 0, 1],\n",
              "       [0, 0, 0, 0],\n",
              "       [0, 0, 0, 0]])"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# generate yeild\n",
        "channel_state = (s for s in sensor)\n",
        "channel_state"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIuuFazfL_6Z",
        "outputId": "c82944f9-c511-4bbb-b5fc-55e898a9eaad"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<generator object <genexpr> at 0x7fab9570e750>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import unittest\n",
        "\n",
        "class TestCS1(unittest.TestCase):\n",
        "  def setUp(self):\n",
        "    nchannels = sensor.shape[1]\n",
        "    self.cs1 = CS1(\"Next State\", nchannels, model_path=\"model.tflite\")\n",
        "\n",
        "  def test_nochannel(self):\n",
        "    selected_channel = [self.cs1.select_channel(next(channel_state)) for _ in range(9)]\n",
        "    self.assertEqual(all(selected_channel), False, \"expected the selected channels to be all none\")\n",
        "\n",
        "  def test_predictions(self):\n",
        "    [self.cs1.select_channel(next(channel_state)) for _ in range(9)]\n",
        "    selected_channel = self.cs1.select_channel(next(channel_state))\n",
        "    self.assertTrue(type(selected_channel) is int or selected_channel is None, \"expected selected channel to be an integer or None\")\n",
        "\n",
        "\n",
        "tests = TestCS1()\n",
        "tests_loaded = unittest.TestLoader().loadTestsFromModule(tests)\n",
        "unittest.TextTestRunner().run(tests_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IXisXjG-I_OZ",
        "outputId": "1721a76a-e266-41c1-e5d4-359839685f7e"
      },
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.016s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class TestCS2(unittest.TestCase):\n",
        "  def setUp(self):\n",
        "    self.cs2 = CS2(\"Idletime\", model_path=\"model2.tflite\")\n",
        "\n",
        "  def test_nochannel(self):\n",
        "    selected_channel = [self.cs2.select_channel(next(channel_state)) for _ in range(8)]\n",
        "    self.assertEqual(all(selected_channel), False, \"expected the selected channels to be all none\")\n",
        "\n",
        "  def test_predictions(self):\n",
        "    [self.cs2.select_channel(next(channel_state)) for _ in range(8)]\n",
        "    selected_channel = self.cs2.select_channel(next(channel_state))\n",
        "    self.assertTrue(type(selected_channel) is int or selected_channel is None, \"expected selected channel to be an integer or None\")\n",
        "\n",
        "\n",
        "tests = TestCS2()\n",
        "tests_loaded = unittest.TestLoader().loadTestsFromModule(tests)\n",
        "unittest.TextTestRunner().run(tests_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "imSXiPI2IMJB",
        "outputId": "aab51874-52f4-4c25-ba4f-aa5f4a0c908a"
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "..\n",
            "----------------------------------------------------------------------\n",
            "Ran 2 tests in 0.021s\n",
            "\n",
            "OK\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<unittest.runner.TextTestResult run=2 errors=0 failures=0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3.9.13 ('tf')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "f3c90792d9706e1521d25cde726ba1df068d4e8485dce7e6bd0a85f1402880b8"
      }
    },
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}